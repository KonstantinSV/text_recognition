{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Распознавание текста .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1t3FZ0NycSbowmG-1i1xpICcQcYkeBRHF",
      "authorship_tag": "ABX9TyM6m8mbqWHbpWOcmLHvp4Wx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonstantinSV/text_recognition/blob/main/%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o_wKASXDHoQ"
      },
      "source": [
        " **Проект: определение рускоязычных токсичных комментариев**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR1LDoS3DjEu"
      },
      "source": [
        "Цель - обучить модель рпределяющую является комментарий токсичным или нет."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ef2q3m-ERqi"
      },
      "source": [
        "Данные для обучения:\r\n",
        "\r\n",
        "Датасет на Kaggle - https://www.kaggle.com/blackmoon/russian-language-toxic-comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tox_DkUO3vKK"
      },
      "source": [
        "# Предварительная обработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtchcIze3WQm"
      },
      "source": [
        "import re\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUdZWzkc3fPR"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/projects/project_text_recognition/labeled.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ5ZYcJv3jAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531b0ba5-4528-42e3-c0ad-74d898f0cb0e"
      },
      "source": [
        "# Размеры DataFrame\r\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14412, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfeW4ZNk3lyC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "08bd6c7e-97cd-48b7-e115-f02ff69e5930"
      },
      "source": [
        "# Первые пять строк DataFrame\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  toxic\n",
              "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
              "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
              "2                          Собаке - собачья смерть\\n    1.0\n",
              "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
              "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jgxrJid3--n"
      },
      "source": [
        "Выделение данных для обучения и  целевого признака."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vKzh1Sq3_Pf"
      },
      "source": [
        "# Данные\r\n",
        "base = data.comment\r\n",
        "\r\n",
        "# Целевой признак\r\n",
        "target = data.toxic.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_mCznhmm2TD",
        "outputId": "9dde28d5-c2b6-48a5-ba9c-b3f1c08efd34"
      },
      "source": [
        "# Сравним соотношение меток класс 0 и класса 1 \r\n",
        "print(data.toxic.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0    9586\n",
            "1.0    4826\n",
            "Name: toxic, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBkqVa6L0ROo"
      },
      "source": [
        "Выделяем столбец, в котором будет указано количество восклицательных знаков в тексте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV9Vu76m0Nly"
      },
      "source": [
        "exclamations = base.apply(lambda x: x.count('!')).rename('num_exclamations')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIAIunJg4r8e"
      },
      "source": [
        "Очистим текст от символов. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_PfQmJJ4y7n"
      },
      "source": [
        "def clear_text(text):\r\n",
        "    return re.sub(r'[\\W]\\s*', ' ', text).lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Atqmj-BB5Cv2"
      },
      "source": [
        "Проверка функции."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G00UfPCd5A5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3835c86e-1bc4-47bf-afe4-370656bbdca3"
      },
      "source": [
        "# Возьмём произвольный текст\r\n",
        "arbitrary_text = data.at[2020, \"comment\"]\r\n",
        "print(f'Исходный текст:\\n\\n{arbitrary_text}\\n')\r\n",
        "print(f\"Очищенный текст:\\n\\n{clear_text(arbitrary_text)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Исходный текст:\n",
            "\n",
            "Вольнова же повесили на параше, ты про что?\n",
            "\n",
            "\n",
            "Очищенный текст:\n",
            "\n",
            "вольнова же повесили на параше ты про что \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMEs44rm5rLW"
      },
      "source": [
        "# Сохраним очищенный текст в переменной base\r\n",
        "base = base.apply(clear_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66BDNNcl6jNn"
      },
      "source": [
        "# Обучение моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp7Q2S_n6lFE"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.naive_bayes import BernoulliNB\r\n",
        "from sklearn.model_selection import train_test_split, cross_validate\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from functools import partial\r\n",
        "from scipy import sparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xZYRnYeOXPv",
        "outputId": "eb40db68-2d5f-46ed-9268-dbb0d12f606e"
      },
      "source": [
        "# Сохраним в переменную stop_en стоп-слова\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "stop_en = nltk.corpus.stopwords.words('russian')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRZI5mfLPDUu"
      },
      "source": [
        "# Функция для лемматизации текста\r\n",
        "def lemmatization(text, lemm_func):\r\n",
        "  return ' '.join(list(map(lemm_func, text.split())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAISEEky6vRK"
      },
      "source": [
        "# Функция обучает модель на данных, преобразованных с помощью объекта vectorizer\r\n",
        "# Функция принимает данные лемматизирует их (если нужно), векторизует тексты в корпусе, выполняет кросс-валидацию модели, измеряет качество предсказаний на тестовой выборке.\r\n",
        "def train_pipeline(model, vectorizer, x, y, with_exclamations=False, lemm_func=None, **kwargs):\r\n",
        "    global exclamations\r\n",
        "    if lemm_func:\r\n",
        "        x = x.copy().apply(lemmatization, lemm_func=lemm_func)\r\n",
        "        \r\n",
        "    # Делим на выборки 3:1\r\n",
        "    x_train, x_test, y_train, y_test, exc_train, exc_test = train_test_split(x, y, exclamations, random_state=0, test_size=.25)\r\n",
        "    # Проверяем качество деления\r\n",
        "    print('train_test_split: ')\r\n",
        "    for x in (x_train, x_test, y_train, y_test, exc_train, exc_test):\r\n",
        "        print(x.shape)\r\n",
        "    # Создаём объект-векторизатор\r\n",
        "    vectorizer = vectorizer(**kwargs)\r\n",
        "    # Преобразуем корпус\r\n",
        "    x_train = vectorizer.fit_transform(x_train)\r\n",
        "    x_test = vectorizer.transform(x_test)\r\n",
        "    # Если используем восклицательные знаки, добавим один столбец к матрице\r\n",
        "    if with_exclamations:\r\n",
        "        x_train = sparse.hstack([x_train, exc_train.values.reshape(-1, 1)], format='csr')\r\n",
        "        x_test = sparse.hstack([x_test, exc_test.values.reshape(-1, 1)], format='csr')\r\n",
        "    display(x_train)\r\n",
        "    # Запишем результат кросс-валидации с метрикой F1\r\n",
        "    print('cross-validating: ')\r\n",
        "    output = cross_validate(model, x_train, y_train, cv=3, n_jobs=-1, scoring='f1')\r\n",
        "    output['cv_score'] = np.mean(output['test_score'])\r\n",
        "    output['fit_time'] = np.mean(output['fit_time'])\r\n",
        "    del output['test_score']\r\n",
        "    # Добавим F1 на тестовой выборке\r\n",
        "    model.fit(x_train, y_train)\r\n",
        "    output['test_score'] = f1_score(y_test, model.predict(x_test))\r\n",
        "    del output['score_time']\r\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BWAuf0AdeKk"
      },
      "source": [
        "# Сохраним в переменную данные для обучения, целевой признак и стоп-слова\r\n",
        "train_vectorized = partial(train_pipeline, x=base, y=target, stop_words=stop_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLSDkiT8BLbn"
      },
      "source": [
        "# Кодирование признаков способом мешок слов (Bag of words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMxxp68n6m81"
      },
      "source": [
        " **Логистическая регрессия.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd_h57rW69oi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "e924644c-b766-4a8e-de02-89afda261154"
      },
      "source": [
        "# Обучение модели с базовыми параметрами\r\n",
        "train_vectorized(LogisticRegression(class_weight='balanced'), vectorizer=CountVectorizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_test_split: \n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<10809x56801 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 173410 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cross-validating: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv_score': 0.7587701230514657,\n",
              " 'fit_time': 0.9655281702677408,\n",
              " 'test_score': 0.7768940979489327}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnvBfyM37B8q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "a0d13ee1-1520-4e18-dc2c-55e8fcc02375"
      },
      "source": [
        "# Обучение модели со стеммингом\r\n",
        "train_vectorized(LogisticRegression(class_weight='balanced'), lemm_func=SnowballStemmer('russian').stem, vectorizer=CountVectorizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_test_split: \n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<10809x28522 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 177779 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cross-validating: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv_score': 0.7977692199878877,\n",
              " 'fit_time': 0.5511995156606039,\n",
              " 'test_score': 0.8091286307053941}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZawJVLI7OYq"
      },
      "source": [
        "Пока что у нас нет веской причины использовать стемминг. Узнаем, насколько хорошо сработает лемматизация."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utXS8sl77QNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "928d3fbd-75a2-4a23-878d-be8d3ca297b8"
      },
      "source": [
        "# Обучение модели с лемматизацией\r\n",
        "train_vectorized(LogisticRegression(class_weight='balanced'), lemm_func=WordNetLemmatizer().lemmatize, vectorizer=CountVectorizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_test_split: \n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<10809x56773 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 173387 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cross-validating: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv_score': 0.758946829435359,\n",
              " 'fit_time': 0.9382328987121582,\n",
              " 'test_score': 0.7755443886097153}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QpSkVFo7lEx"
      },
      "source": [
        "**Наивный Байес**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBPjmHZb7zm5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "8a9a5531-b859-4464-d8fb-e3dce61c7d7f"
      },
      "source": [
        "# Обучение Байеса\r\n",
        "train_vectorized(BernoulliNB(), vectorizer=CountVectorizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_test_split: \n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<10809x56801 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 173410 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cross-validating: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv_score': 0.3595160933246548,\n",
              " 'fit_time': 0.015131711959838867,\n",
              " 'test_score': 0.498159509202454}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1KQd74PBfvl"
      },
      "source": [
        "Промежуточный вывод:\r\n",
        "1. Байес работает быстрее логистической регрессии, но результаты логистической регрессии лучше чем Байеса.\r\n",
        "2. Обучение логистической регрессии со стеммингом дало наилучший результат.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQO3Vf_fA0wR"
      },
      "source": [
        "# ТF-IDF-кодирование признаков."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKTCxqbX8BtA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "70837e82-d07d-4f22-af5f-689f0ffa6ede"
      },
      "source": [
        "# Обучение модели с базовыми параметрами\r\n",
        "train_vectorized(LogisticRegression(class_weight='balanced'), vectorizer=TfidfVectorizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_test_split: \n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<10809x56801 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 173410 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cross-validating: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv_score': 0.7706427965643624,\n",
              " 'fit_time': 0.3012491861979167,\n",
              " 'test_score': 0.7855626326963906}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RJvr0Jm8INo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "13c5bec7-703b-451d-dd45-259b49bfbba8"
      },
      "source": [
        "# Обучение модели с восклицательными знаками\r\n",
        "train_vectorized(LogisticRegression(class_weight='balanced'), vectorizer=TfidfVectorizer, with_exclamations=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_test_split: \n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<10809x56802 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 174223 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cross-validating: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv_score': 0.7700073689809251,\n",
              " 'fit_time': 0.7238573233286539,\n",
              " 'test_score': 0.7906382978723403}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km_OygW98Km5"
      },
      "source": [
        "Модель с восклицательными знаками показала себя лучше базовой\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG3k0CG78MlR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "06a8b69b-744f-4212-a8a3-62bd9cea818d"
      },
      "source": [
        "# Обучение модели со стеммингом\r\n",
        "train_vectorized(LogisticRegression(class_weight='balanced'), vectorizer=TfidfVectorizer, lemm_func=SnowballStemmer('russian').stem)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_test_split: \n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<10809x28522 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 177779 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cross-validating: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv_score': 0.8156560792470743,\n",
              " 'fit_time': 0.2217536767323812,\n",
              " 'test_score': 0.8262833675564683}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fr7IeQX8OOw"
      },
      "source": [
        "Результаты слегка улучшились, но средняя F1 при кросс-валидации по-прежнему ниже требуемого значения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JdFtP4L8QF4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "0b6cf7d6-95c4-46cb-a536-a090fa6847a2"
      },
      "source": [
        "# Обучение модели с лемматизацией\r\n",
        "train_vectorized(LogisticRegression(class_weight='balanced'), vectorizer=TfidfVectorizer, lemm_func=WordNetLemmatizer().lemmatize, with_exclamations=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_test_split: \n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n",
            "(10809,)\n",
            "(3603,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<10809x56774 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 174200 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cross-validating: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv_score': 0.7701167073881269,\n",
              " 'fit_time': 0.6302946408589681,\n",
              " 'test_score': 0.7911527009783071}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAX4-Mwp2MKy"
      },
      "source": [
        "При кодировании ТF-IDF, модель со стеммингом показала результаты хуже чем с мешком слов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQCHDpY_8aIA"
      },
      "source": [
        "Выводы и наблюдения:\r\n",
        "\r\n",
        "Эффективнее остальных себя показал TfidfVectorizer, потому что с этим способом кодирования признаков F1 при кросс-валидации и F1 на тестовой выборке показывают самые лучшие результаты. \r\n",
        "Стемминг улучшил результаты в как с мешком слов, так и с TF-IDF.\r\n",
        "Лемматизация показала себя хуже стемминга в обоих случаях.\r\n",
        "Восклицательные знаки как признак не сыграли большой роли для качества предсказаний.\r\n",
        "\r\n",
        "Лучший результат на данном этапе дают логистическая регрессия и TF-IDF со стеммингом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk4HAKrV9vJA"
      },
      "source": [
        "# 3. Подбор гиперпараметров\r\n",
        "Было применено два способа преобразования текстов для машинного обучения, и наиболее эффективным вариантом себя показала логистическая регрессия и TF-IDF со стеммингом. Для улучшения качества модели оптимизируем гиперпараметры."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM5HDKOm91st",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d00df530-110e-4808-ad8e-0ec108670f9a"
      },
      "source": [
        "# Деление на обучающую и тестовую выборки \r\n",
        "xtr_final, xts_final, ytr_final, yts_final = train_test_split(base, target, random_state=0, test_size=0.2)\r\n",
        "for df in (xtr_final, xts_final, ytr_final, yts_final):\r\n",
        "    print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11529,)\n",
            "(2883,)\n",
            "(11529,)\n",
            "(2883,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm20LmpiN8iG"
      },
      "source": [
        "# Проведение стемминга\r\n",
        "def preprocessor(text, lemm_func):\r\n",
        "  return ' '.join(list(map(lemm_func, text.split())))\r\n",
        "\r\n",
        "xtr_final = xtr_final.copy().apply(preprocessor, lemm_func=SnowballStemmer('russian').stem)\r\n",
        "xts_final = xts_final.copy().apply(preprocessor, lemm_func=SnowballStemmer('russian').stem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m-V_KqSL0oy"
      },
      "source": [
        "# Векторизация текстов\r\n",
        "cvect = TfidfVectorizer(stop_words=stop_en)\r\n",
        "xtr_final = cvect.fit_transform(xtr_final)\r\n",
        "xts_final = cvect.transform(xts_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X36bdYV94sH"
      },
      "source": [
        "Лемматизацию и восклицательные знаки делать не будем. Эти операции не будут иметь большого смысла."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkyd7KGaEvDv"
      },
      "source": [
        "# Создание GridSearch\r\n",
        "grid = GridSearchCV(LogisticRegression(),\r\n",
        "                        {'class_weight': ['balanced', None],\r\n",
        "                         'solver': ['liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs'],\r\n",
        "                         'C': np.arange(0.1, 1.1, 0.1)}, scoring='f1', cv=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05MnrGEnFNYg",
        "outputId": "82e92406-b60f-428d-f54b-a5cba253c54d"
      },
      "source": [
        "# Обучение GridSearch\r\n",
        "grid.fit(xtr_final, ytr_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              "                         'class_weight': ['balanced', None],\n",
              "                         'solver': ['liblinear', 'newton-cg', 'sag', 'saga',\n",
              "                                    'lbfgs']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6-ZmKVTG2-d",
        "outputId": "7dc44d59-cf6e-466e-ff7d-d4761e085221"
      },
      "source": [
        "# Лучшие гиперпараметры подобранные GridSearch\r\n",
        "grid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.0, 'class_weight': 'balanced', 'solver': 'saga'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF85gZTt99q8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f07487c-62fd-48ce-9741-02d26d78b803"
      },
      "source": [
        "# Лучший результат кросс-валидации\r\n",
        "grid.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8177946323065487"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brE-h14j-C_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51c2eef-1cda-4953-c7fe-3fce4d54fd57"
      },
      "source": [
        "# F1 на тестовой выборке\r\n",
        "f1_score(yts_final, grid.predict(xts_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8292433537832311"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    }
  ]
}